{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161 : information visualization\n",
      "148 : visualization\n",
      "139 : volume rendering\n",
      "123 : visual analytics\n",
      "78  : flow visualization\n",
      "55  : scientific visualization\n",
      "52  : volume visualization\n",
      "49  : data visualization\n",
      "48  : interaction\n",
      "36  : evaluation\n",
      "32  : clustering\n",
      "31  : direct volume rendering\n",
      "27  : uncertainty visualization\n",
      "26  : graph visualization\n",
      "25  : isosurfaces\n",
      "24  : parallel coordinates\n",
      "23  : perception\n",
      "23  : virtual reality\n",
      "21  : user study\n",
      "21  : feature extraction\n"
     ]
    }
   ],
   "source": [
    "import pymysql.cursors\n",
    "from collections import Counter\n",
    "import pprint\n",
    "connection = pymysql.connect(host='127.0.0.1',\n",
    "                             user='ieeevis',\n",
    "                             password='ieeevis',\n",
    "                             db='ieeevis',\n",
    "                             charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "with connection.cursor() as cursor:\n",
    "    # Read a single record\n",
    "    sql = \"SELECT `Author Keywords` FROM `main`\"\n",
    "    cursor.execute(sql, ())\n",
    "    result = cursor.fetchall()\n",
    "    keywords = []\n",
    "    for x in [y['Author Keywords'].split(',') for y in result]:\n",
    "        for z in x:\n",
    "            if len(z.strip()) != 0:\n",
    "                keywords.append(str(z.strip().lower()))\n",
    "    result = dict(zip(Counter(keywords).keys(),Counter(keywords).values()))\n",
    "    for k,v in Counter(keywords).most_common(20):\n",
    "        print(\"{:<4}: {:}\".format(str(v),str(k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80  : visual analytics\n",
      "55  : information visualization\n",
      "46  : visualization\n",
      "29  : interaction\n",
      "26  : volume rendering\n",
      "22  : evaluation\n",
      "18  : uncertainty visualization\n",
      "18  : flow visualization\n",
      "15  : design study\n",
      "13  : direct volume rendering\n",
      "11  : parallel coordinates\n",
      "11  : graph visualization\n",
      "11  : visual knowledge discovery\n",
      "11  : clustering\n",
      "11  : sensemaking\n",
      "10  : perception\n",
      "10  : uncertainty\n",
      "10  : user study\n",
      "10  : design\n",
      "9   : multivariate data\n"
     ]
    }
   ],
   "source": [
    "with connection.cursor() as cursor:\n",
    "    # Read a single record\n",
    "    sql = \"SELECT `Author Keywords` FROM `main` where `Year`>=2010\"\n",
    "    cursor.execute(sql, ())\n",
    "    result = cursor.fetchall()\n",
    "    keywords = []\n",
    "    for x in [y['Author Keywords'].split(',') for y in result]:\n",
    "        for z in x:\n",
    "            if len(z.strip()) != 0:\n",
    "                keywords.append(str(z.strip().lower()))\n",
    "    result = dict(zip(Counter(keywords).keys(),Counter(keywords).values()))\n",
    "    for k,v in Counter(keywords).most_common(20):\n",
    "        print(\"{:<4}: {:}\".format(str(v),str(k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449\n",
      "All keywords: 8840\n",
      "Unique keywords: 4658\n",
      "Total paper: 2752\n",
      "Empty keywords (before lookup): 913\n"
     ]
    }
   ],
   "source": [
    "# get all the keywords, make keywords from abstract based on existing keywords if empty\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "keywords_unique = []\n",
    "with connection.cursor() as cursor:\n",
    "    sql = \"SELECT `Author Keywords` FROM `main`\"\n",
    "    sql2 = \"SELECT `Abstract` FROM `main`\"\n",
    "    sql3 = \"SELECT `Paper Title` FROM `main`\"\n",
    "    cursor.execute(sql, ())\n",
    "    # result is a list\n",
    "    result = cursor.fetchall()\n",
    "    \n",
    "    cursor.execute(sql2, ())\n",
    "    # result is a list\n",
    "    abstract = cursor.fetchall()\n",
    "    \n",
    "    cursor.execute(sql3, ())\n",
    "    # result is a list\n",
    "    titles = cursor.fetchall()\n",
    "    \n",
    "#     tokens = word_tokenize(abstract[0]['Abstract'])\n",
    "#     tokens = [str(token) for token in tokens if token not in stopwords.words('english') and token not in [',','.','\\'','\\'s']]\n",
    "#     print tokens\n",
    "    \n",
    "    keywords = []\n",
    "    paper_keywords = []\n",
    "    for x in [y['Author Keywords'].split(',') for y in result]:\n",
    "        if \"data\" in [re.sub(r'\\s+',' ',str(w.strip().lower())) for w in x]:\n",
    "            print len(paper_keywords)\n",
    "        paper_keywords.append([re.sub(r'\\s+',' ',str(w.strip().lower())) for w in x])\n",
    "        for z in x:\n",
    "            if len(z.strip()) != 0:\n",
    "                keywords.append(str(z.strip().lower()))\n",
    "    print \"All keywords:\",len(keywords)\n",
    "        \n",
    "    keywords_unique = list(set(keywords))\n",
    "    print \"Unique keywords:\",len(keywords_unique)\n",
    "    \n",
    "    print \"Total paper:\",len(paper_keywords)\n",
    "    \n",
    "    print \"Empty keywords (before lookup):\",paper_keywords.count([''])\n",
    "    \n",
    "#     print \"====================\"\n",
    "    \n",
    "#     final_keywords = []\n",
    "#     for index,obj in enumerate(paper_keywords):\n",
    "#         temp = []\n",
    "#         for x in keywords_unique:\n",
    "#             if \" \"+x+\" \" in abstract[index]['Abstract'].lower():\n",
    "#                 temp.append(x)\n",
    "#         if len(obj)==0 or (len(obj)==1 and obj[0]==\"\"):\n",
    "#             final_keywords.append(temp)\n",
    "#             if len(temp) == 0:\n",
    "#                 print titles[index]['Paper Title']\n",
    "#         else:\n",
    "#             final_keywords.append(list(set().union(obj,temp)))\n",
    "        \n",
    "# #     print \"====================\"\n",
    "        \n",
    "#     print \"Empty keywords (after lookup):\",final_keywords.count([])\n",
    "            \n",
    "#     print final_keywords\n",
    "    \n",
    "#     result = dict(zip(Counter(keywords).keys(),Counter(keywords).values()))\n",
    "#     for k,v in Counter(keywords).most_common(20):\n",
    "#         print(\"{:<4}: {:}\".format(str(v),str(k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4658\n"
     ]
    }
   ],
   "source": [
    "target = open('./keywords', 'w')\n",
    "for x in keywords_unique:\n",
    "    target.write(x)\n",
    "    target.write(\"\\n\")\n",
    "target.close()\n",
    "print len(keywords_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9676\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "with connection.cursor() as cursor:\n",
    "    # Read a single record\n",
    "    sql = \"SELECT `Author Names` FROM `main`\"\n",
    "    cursor.execute(sql, ())\n",
    "    result = cursor.fetchall()\n",
    "    authors = []\n",
    "    for x in [y['Author Names'].split(';') for y in result]:\n",
    "        for z in x:\n",
    "            authors.append(z.strip())\n",
    "\n",
    "\n",
    "        \n",
    "    target = codecs.open('./output2', 'w', \"utf-8\")\n",
    "    for x in list(set(authors)):\n",
    "        target.write(x)\n",
    "        target.write(\"\\n\")\n",
    "    target.close()\n",
    "    print len(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9666\n"
     ]
    }
   ],
   "source": [
    "# Data facts:\n",
    "# Some Author ID is empty, not even having \";\"\n",
    "import codecs\n",
    "with connection.cursor() as cursor:\n",
    "    # Read a single record\n",
    "    name_id = {}\n",
    "    sql = \"SELECT `Deduped author names` FROM `main`\"\n",
    "    cursor.execute(sql, ())\n",
    "    result = cursor.fetchall()\n",
    "    y = []\n",
    "    for x in result:\n",
    "        for z in x['Deduped author names'].split(';'):\n",
    "            y.append(z)\n",
    "    print len(y)\n",
    "    y = list(set(y))\n",
    "    target = codecs.open(\"./authors\", \"w\", \"utf8\")\n",
    "    for x in sorted(y):\n",
    "        target.write(x)\n",
    "        target.write(\"\\n\")\n",
    "    target.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
